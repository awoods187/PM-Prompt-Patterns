# Gemini 2.5 Pro Model Definition
# Last verified: 2025-10-25
# Source: https://ai.google.dev/gemini-api/docs/models/gemini

schema_version: "1.0.0"
model_id: "gemini-2-5-pro"
provider: "google"
name: "Gemini 2.5 Pro"
api_identifier: "gemini-2.5-pro-002"

metadata:
  context_window_input: 2000000
  context_window_output: 8192
  knowledge_cutoff: "August 2024"
  release_date: "2024-12-01"
  last_verified: "2025-10-25"
  docs_url: "https://ai.google.dev/gemini-api/docs/models/gemini"

capabilities:
  - text_input
  - text_output
  - function_calling
  - vision
  - large_context
  - prompt_caching
  - streaming
  - json_mode
  - code_execution

pricing:
  input_per_1m: 1.25
  output_per_1m: 5.00
  cache_write_per_1m: 3.13
  cache_read_per_1m: 0.31

optimization:
  recommended_for:
    - "Massive context processing (up to 2M tokens)"
    - "Long document analysis"
    - "Codebase understanding"
    - "Multi-file reasoning"
    - "Research paper analysis"
    - "Book summarization"
  best_practices:
    - "Leverage 2M token context for comprehensive analysis"
    - "Use context caching for large repeated contexts"
    - "Native code execution capability"
    - "Excellent for multi-document tasks"
    - "Use for processing entire codebases"
    - "Strong at long-form content generation"
  cost_tier: "mid-tier"
  speed_tier: "balanced"

notes: "Industry-leading 2M token context window. Excellent for processing large documents and codebases."
